#find optimal lambda value that minimizes test MSE
best_lambda_CP <- CP_cv_model$lambda.min
best_lambda_CP
#find coefficients of best model
best_model_CP <- glmnet(x_CP, y_CP, alpha = 1, lambda = best_lambda_CP)
shiny::runApp('~/Grinnell College/Semester 5/Software Development/Coffee_Quality/coffee')
# variable list
# vars <- c("aroma", "flavor")
vars <- list("world2@data$aroma", "world2@data$flavor")
# variable list
# vars <- c("aroma", "flavor")
vars <- list("world2@data$aroma", "world2@data$flavor")
setwd("~/Grinnell College/Semester 5/Software Development/Coffee_Quality/coffee")
setwd("~/Grinnell College/Semester 5/Software Development/Coffee_Quality/coffee")
setwd("~/Grinnell College/Semester 5/Data Science/230_Final_Project/230_Final_Project")
# Libraries
library(tidyverse)
library(caret)
library(caTools)
library(corrgram)
library(leaps)
library(repr)
library(glmnet)
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
modelEval <- as.data.frame(modelEval)
head(modelEval)
linear_m_mse <- mean((modelEval$actual - modelEval$predicted)**2)
linear_m_rmse <- sqrt(linear_m_mse)
subsets <- regsubsets(CO2_PC~., data = trainSet, nvmax = 22)
res.sum <- summary(subsets)
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic)
)
trainSet_CP <- trainSet %>%
select(-Milk_Prod, -Wind_Energy, - Potassium_Fert_Cons, -Phosphate_Fert_Cons)
model_CP <- lm(formula = CO2_PC ~ ., data = trainSet_CP)
residuals_model_CP <- as.data.frame(residuals(model_CP))
ggplot(residuals_model_CP, aes(x = residuals(model_CP),)) +
geom_histogram()
preds_CP <- predict(model_CP, testSet)
modelEval_CP<- cbind(testSet$CO2_PC, preds_CP)
colnames(modelEval_CP) <- c("actual", "predicted")
modelEval_CP <- as.data.frame(modelEval_CP)
head(modelEval_CP)
CP_mse <- mean((modelEval_CP$actual - modelEval_CP$predicted)**2)
CP_rmse <- sqrt(CP_mse)
trainSet_BIC <- trainSet %>%
select(-Larynx_Cancer_Deaths,-Potassium_Fert_Cons,
- Phosphate_Fert_Cons,-Wind_Energy, -Other_Energy,
- Milk_Prod)
model_BIC <- lm(formula =  CO2_PC ~., data = trainSet_BIC)
### Residuals
residuals_model_BIC <- as.data.frame(residuals(model_BIC))
ggplot(residuals_model_BIC, aes(x = residuals(model_BIC),)) +
geom_histogram()
preds_BIC <- predict(model_BIC, testSet)
modelEval_BIC<- cbind(testSet$CO2_PC, preds_BIC)
colnames(modelEval_BIC) <- c("actual", "predicted")
modelEval_BIC <- as.data.frame(modelEval_BIC)
head(modelEval_BIC)
BIC_mse <- mean((modelEval_BIC$actual - modelEval_BIC$predicted)**2)
BIC_rmse <- sqrt(BIC_mse)
rmse_vals <- c(linear_m_rmse, CP_rmse, BIC_rmse)
y <- trainSet$CO2_PC
x <- data.matrix(cbind(trainSet[1],trainSet[3:21]))
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
preds_lasso <- predict(best_model, data.matrix(cbind(testSet[1],testSet[3:21])), s = best_lambda)
modelEval_lasso<- cbind(testSet$CO2_PC, preds_lasso)
library(repr)
library(glmnet)
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
modelEval <- as.data.frame(modelEval)
head(modelEval)
linear_m_mse <- mean((modelEval$actual - modelEval$predicted)**2)
linear_m_rmse <- sqrt(linear_m_mse)
subsets <- regsubsets(CO2_PC~., data = trainSet, nvmax = 22)
res.sum <- summary(subsets)
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic)
)
trainSet_CP <- trainSet %>%
select(-Milk_Prod, -Wind_Energy, - Potassium_Fert_Cons, -Phosphate_Fert_Cons)
model_CP <- lm(formula = CO2_PC ~ ., data = trainSet_CP)
residuals_model_CP <- as.data.frame(residuals(model_CP))
ggplot(residuals_model_CP, aes(x = residuals(model_CP),)) +
geom_histogram()
View(model)
source("~/Grinnell College/Semester 5/Data Science/230_Final_Project/230_Final_Project/Modelling.R")
source("~/Grinnell College/Semester 5/Data Science/230_Final_Project/230_Final_Project/Modelling.R")
View(best_model)
View(cv_model)
View(model)
View(modelEval_BIC)
View(model)
View(model_BIC)
View(modelEval_CP)
View(model_CP)
View(modelEval)
model_BIC[["coefficients"]][["Hydro_Energy"]]
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
modelEval <- as.data.frame(modelEval)
head(modelEval)
linear_m_mse <- mean((modelEval$actual - modelEval$predicted)**2)
linear_m_rmse <- sqrt(linear_m_mse)
subsets <- regsubsets(CO2_PC~., data = trainSet, nvmax = 22)
res.sum <- summary(subsets)
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic)
)
trainSet_CP <- trainSet %>%
select(-Milk_Prod, -Wind_Energy, - Potassium_Fert_Cons, -Phosphate_Fert_Cons)
model_CP <- lm(formula = CO2_PC ~ ., data = trainSet_CP)
residuals_model_CP <- as.data.frame(residuals(model_CP))
ggplot(residuals_model_CP, aes(x = residuals(model_CP),)) +
geom_histogram()
preds_CP <- predict(model_CP, testSet)
modelEval_CP<- cbind(testSet$CO2_PC, preds_CP)
colnames(modelEval_CP) <- c("actual", "predicted")
modelEval_CP <- as.data.frame(modelEval_CP)
head(modelEval_CP)
CP_mse <- mean((modelEval_CP$actual - modelEval_CP$predicted)**2)
CP_rmse <- sqrt(CP_mse)
trainSet_BIC <- trainSet %>%
select(-Larynx_Cancer_Deaths,-Potassium_Fert_Cons,
- Phosphate_Fert_Cons,-Wind_Energy, -Other_Energy,
- Milk_Prod)
model_BIC <- lm(formula =  CO2_PC ~., data = trainSet_BIC)
### Residuals
residuals_model_BIC <- as.data.frame(residuals(model_BIC))
ggplot(residuals_model_BIC, aes(x = residuals(model_BIC),)) +
geom_histogram()
preds_BIC <- predict(model_BIC, testSet)
modelEval_BIC<- cbind(testSet$CO2_PC, preds_BIC)
colnames(modelEval_BIC) <- c("actual", "predicted")
modelEval_BIC <- as.data.frame(modelEval_BIC)
head(modelEval_BIC)
BIC_mse <- mean((modelEval_BIC$actual - modelEval_BIC$predicted)**2)
BIC_rmse <- sqrt(BIC_mse)
rmse_vals <- c(linear_m_rmse, CP_rmse, BIC_rmse)
y <- trainSet$CO2_PC
x <- data.matrix(cbind(trainSet[1],trainSet[3:21]))
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
preds_lasso <- predict(best_model, data.matrix(cbind(testSet[1],testSet[3:21])), s = best_lambda)
modelEval_lasso<- cbind(testSet$CO2_PC, preds_lasso)
colnames(modelEval_lasso) <- c("actual", "predicted")
modelEval_lasso <- as.data.frame(modelEval_lasso)
lasso_mse <- mean((modelEval_lasso$actual - modelEval_lasso$predicted)**2)
lasso_rmse <- sqrt(lasso_mse)
###############################################################
# ### BIC variables
# ### BIC variables
#
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# ### BIC variables
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
#
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
# best_lambda_BIC <- BIC_cv_model$lambda.min
# y_BIC <- trainSet$CO2_PC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
# best_lambda_BIC <- BIC_cv_model$lambda.min
# best_lambda_BIC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
# best_lambda_BIC <- BIC_cv_model$lambda.min
# best_lambda_BIC
#
# x_BIC <- data.matrix(cbind(trainSet[1],trainSet[3:16]))
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
# best_lambda_BIC <- BIC_cv_model$lambda.min
# best_lambda_BIC
#
# #find coefficients of best model
#
# #perform k-fold cross-validation to find optimal lambda value
# BIC_cv_model <- cv.glmnet(x_BIC, y_BIC, alpha = 1)
#
# #find optimal lambda value that minimizes test MSE
# best_lambda_BIC <- BIC_cv_model$lambda.min
# best_lambda_BIC
#
# #find coefficients of best model
# best_model_BIC <- glmnet(x_BIC, y_BIC, alpha = 1, lambda = best_lambda_BIC)
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
modelEval<- cbind(testSet$CO2_PC, preds)
modelEval<- cbind(testSet$CO2_PC, preds)
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
modelEval <- as.data.frame(modelEval)
head(modelEval)
linear_m_mse <- mean((modelEval$actual - modelEval$predicted)**2)
linear_m_rmse <- sqrt(linear_m_mse)
subsets <- regsubsets(CO2_PC~., data = trainSet, nvmax = 22)
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
source("~/Grinnell College/Semester 5/Data Science/230_Final_Project/230_Final_Project/Modelling.R")
View(lasso_model)
View(residuals_model)
View(residuals_model_BIC)
coef(best_model)
preds_lasso <- predict(lasso_model, data.matrix(cbind(testSet[1],testSet[3:21])), s = best_lambda)
modelEval_lasso<- cbind(testSet$CO2_PC, preds_lasso)
colnames(modelEval_lasso) <- c("actual", "predicted")
modelEval_lasso <- as.data.frame(modelEval_lasso)
lasso_mse <- mean((modelEval_lasso$actual - modelEval_lasso$predicted)**2)
lasso_rmse <- sqrt(lasso_mse)
###############################################################
# ### BIC variables
# ### BIC variables
#
residuals_model_CP <- as.data.frame(residuals(model_CP))
ggplot(residuals_model_CP, aes(x = residuals(model_CP),)) +
geom_histogram()
#find coefficients of best model
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)
preds_lasso <- predict(lasso_model, data.matrix(cbind(testSet[1],testSet[3:21])), s = best_lambda)
modelEval_lasso<- cbind(testSet$CO2_PC, preds_lasso)
colnames(modelEval_lasso) <- c("actual", "predicted")
modelEval_lasso <- as.data.frame(modelEval_lasso)
lasso_mse <- mean((modelEval_lasso$actual - modelEval_lasso$predicted)**2)
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
# Libraries
library(tidyverse)
library(caret)
library(caTools)
library(corrgram)
library(leaps)
library(repr)
library(glmnet)
final <- read_csv("data/final.csv") %>%
select(-Country, -Code)
final[is.na(final)] <- 0
corrgram(final, lower.panel = panel.shade, upper.panel = panel.cor)
set.seed(42)
sampleSplit <- sample.split(Y = final$CO2_PC, SplitRatio = 0.7)
trainSet <- subset(x = final, sampleSplit == TRUE)
testSet <- subset(x = final, sampleSplit == FALSE)
model <- lm(formula = CO2_PC ~ ., data = trainSet)
residuals_model <- as.data.frame(residuals(model))
ggplot(residuals_model, aes(x = residuals(model),)) +
geom_histogram()
preds <- predict(model, testSet)
modelEval<- cbind(testSet$CO2_PC, preds)
colnames(modelEval) <- c("actual", "predicted")
modelEval <- as.data.frame(modelEval)
head(modelEval)
linear_m_mse <- mean((modelEval$actual - modelEval$predicted)**2)
linear_m_rmse <- sqrt(linear_m_mse)
subsets <- regsubsets(CO2_PC~., data = trainSet, nvmax = 22)
res.sum <- summary(subsets)
data.frame(
Adj.R2 = which.max(res.sum$adjr2),
CP = which.min(res.sum$cp),
BIC = which.min(res.sum$bic)
)
trainSet_CP <- trainSet %>%
select(-Milk_Prod, -Wind_Energy, - Potassium_Fert_Cons, -Phosphate_Fert_Cons)
model_CP <- lm(formula = CO2_PC ~ ., data = trainSet_CP)
residuals_model_CP <- as.data.frame(residuals(model_CP))
ggplot(residuals_model_CP, aes(x = residuals(model_CP),)) +
geom_histogram()
preds_CP <- predict(model_CP, testSet)
modelEval_CP<- cbind(testSet$CO2_PC, preds_CP)
colnames(modelEval_CP) <- c("actual", "predicted")
modelEval_CP <- as.data.frame(modelEval_CP)
head(modelEval_CP)
CP_mse <- mean((modelEval_CP$actual - modelEval_CP$predicted)**2)
CP_rmse <- sqrt(CP_mse)
trainSet_BIC <- trainSet %>%
select(-Larynx_Cancer_Deaths,-Potassium_Fert_Cons,
- Phosphate_Fert_Cons,-Wind_Energy, -Other_Energy,
- Milk_Prod)
model_BIC <- lm(formula =  CO2_PC ~., data = trainSet_BIC)
### Residuals
residuals_model_BIC <- as.data.frame(residuals(model_BIC))
ggplot(residuals_model_BIC, aes(x = residuals(model_BIC),)) +
geom_histogram()
preds_BIC <- predict(model_BIC, testSet)
modelEval_BIC<- cbind(testSet$CO2_PC, preds_BIC)
colnames(modelEval_BIC) <- c("actual", "predicted")
modelEval_BIC <- as.data.frame(modelEval_BIC)
head(modelEval_BIC)
BIC_mse <- mean((modelEval_BIC$actual - modelEval_BIC$predicted)**2)
BIC_rmse <- sqrt(BIC_mse)
rmse_vals <- c(linear_m_rmse, CP_rmse, BIC_rmse)
y <- trainSet$CO2_PC
x <- data.matrix(cbind(trainSet[1],trainSet[3:21]))
#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
#find coefficients of best model
lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(lasso_model)
preds_lasso <- predict(lasso_model, data.matrix(cbind(testSet[1],testSet[3:21])), s = best_lambda)
modelEval_lasso<- cbind(testSet$CO2_PC, preds_lasso)
colnames(modelEval_lasso) <- c("actual", "predicted")
modelEval_lasso <- as.data.frame(modelEval_lasso)
lasso_mse <- mean((modelEval_lasso$actual - modelEval_lasso$predicted)**2)
lasso_rmse <- sqrt(lasso_mse)
## R2 Plot
ggplot(modelEval, aes(x= predicted, y = actual)) +
geom_point(color = "lightblue") +
geom_abline(slope = 1, intercept = 0, color = "black", size =1) +
labs(title = "Best R-squared Linear Regression Model",
x = "Predicted Values",
y = "Actual Values") +
theme_classic()
## BIC Plot
ggplot(modelEval_BIC, aes(x= predicted, y = actual)) +
geom_point(color = "lightblue") +
geom_abline(slope = 1, intercept = 0, color = "black", size =1) +
labs(title = "Best BIC Linear Regression Model",
x = "Predicted Values",
y = "Actual Values") +
theme_classic()
## CP Plot
ggplot(modelEval_CP, aes(x= predicted, y = actual)) +
geom_point(color = "lightblue") +
geom_abline(slope = 1, intercept = 0, color = "black", size =1) +
labs(title = "Best CP Linear Regression Model",
x = "Predicted Values",
y = "Actual Values") +
theme_classic()
## Lasso regression
ggplot(modelEval_lasso, aes(x= predicted, y = actual)) +
geom_point(color = "lightblue") +
geom_abline(slope = 1, intercept = 0, color = "black", size =1) +
labs(title = "Lasso Regression Model",
x = "Predicted Values",
y = "Actual Values") +
theme_classic()
head(modelEval_lasso)
lasso_residuals <- data.frame(modelEval_lasso$actual - modelEval_lasso$predicted)
colnames(lasso_residuals) <- c("Residual")
ggplot(lasso_residuals, aes(x = Residual)) +
geom_histogram()
runApp('~/Grinnell College/Semester 5/Software Development/Coffee_Quality/coffee')
